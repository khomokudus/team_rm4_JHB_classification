{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Worth a read whether you do or don't believe in climate change https://t.co/ggLZVNYjun https://t.co/7AFE2mAH8j\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##checking null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_index = [i[0] for i in df.itertuples() if i[2].isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df['message']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1_clf = Pipeline([('vectorizer',TfidfVectorizer(stop_words='english',strip_accents='ascii')),('clf',LinearSVC())])\n",
    "txt2_clf = Pipeline([('vectorizer',TfidfVectorizer(stop_words='english',strip_accents='ascii')),('clf',MultinomialNB())])\n",
    "txt3_clf = Pipeline([('vectorizer',TfidfVectorizer(stop_words='english',strip_accents='ascii')),('clf',RandomForestClassifier(n_estimators=100))])\n",
    "txt4_clf = Pipeline([('vectorizer',TfidfVectorizer(stop_words='english',strip_accents='ascii')),('clf',SVC(C=1.0,probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_all(lst,X,y):\n",
    "    lis = []\n",
    "    for pip in lst:\n",
    "        pip.fit(X,y)\n",
    "        lis.append(pip)\n",
    "    return lis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1437795\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "trained=fit_all([txt1_clf,txt2_clf,txt3_clf,txt4_clf],X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(memory=None,\n",
       "      steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...ax_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0))]),\n",
       " Pipeline(memory=None,\n",
       "      steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...rue,\n",
       "         vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       " Pipeline(memory=None,\n",
       "      steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...obs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False))]),\n",
       " Pipeline(memory=None,\n",
       "      steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...bf', max_iter=-1, probability=True, random_state=None,\n",
       "   shrinking=True, tol=0.001, verbose=False))])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LinearSV\n",
    "pip1_prediction = trained[0].predict(X_test)\n",
    "##Naive\n",
    "pip2_prediction = trained[1].predict(X_test)\n",
    "##Random forest\n",
    "pip3_prediction = trained[2].predict(X_test)\n",
    "##SVC\n",
    "pip4_prediction = trained[3].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSV\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.48      0.59       428\n",
      "           0       0.60      0.42      0.50       737\n",
      "           1       0.78      0.84      0.81      2861\n",
      "           2       0.70      0.78      0.74      1195\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      5221\n",
      "   macro avg       0.71      0.63      0.66      5221\n",
      "weighted avg       0.73      0.74      0.73      5221\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.01      0.03       428\n",
      "           0       1.00      0.06      0.11       737\n",
      "           1       0.60      0.99      0.75      2861\n",
      "           2       0.90      0.33      0.48      1195\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5221\n",
      "   macro avg       0.87      0.35      0.34      5221\n",
      "weighted avg       0.76      0.63      0.54      5221\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.22      0.35       428\n",
      "           0       0.55      0.36      0.44       737\n",
      "           1       0.68      0.89      0.77      2861\n",
      "           2       0.77      0.57      0.66      1195\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5221\n",
      "   macro avg       0.71      0.51      0.55      5221\n",
      "weighted avg       0.70      0.69      0.66      5221\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       428\n",
      "           0       0.00      0.00      0.00       737\n",
      "           1       0.55      1.00      0.71      2861\n",
      "           2       0.00      0.00      0.00      1195\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5221\n",
      "   macro avg       0.14      0.25      0.18      5221\n",
      "weighted avg       0.30      0.55      0.39      5221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1437795\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('LinearSV')\n",
    "print(classification_report(y_test,pip1_prediction))\n",
    "print('\\n\\n')\n",
    "print('Naive')\n",
    "print(classification_report(y_test,pip2_prediction))\n",
    "print('\\n\\n')\n",
    "print('Random forest')\n",
    "print(classification_report(y_test,pip3_prediction))\n",
    "print('\\n\\n')\n",
    "print('SVC')\n",
    "print(classification_report(y_test,pip4_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSV\n",
      "0.748898678414097\n",
      "\n",
      "\n",
      "\n",
      "Naive\n",
      "0.6198046351273703\n",
      "\n",
      "\n",
      "\n",
      "Random forest\n",
      "0.7077188278107642\n"
     ]
    }
   ],
   "source": [
    "##testing Accuracy score\n",
    "print('LinearSV')\n",
    "print(accuracy_score(y_test,pip1_prediction))\n",
    "print('\\n\\n')\n",
    "print('Naive')\n",
    "print(accuracy_score(y_test,pip2_prediction))\n",
    "print('\\n\\n')\n",
    "print('Random forest')\n",
    "print(accuracy_score(y_test,pip3_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LinearSV\n",
    "pip1_predictiont = trained[0].predict(X_train)\n",
    "##Naive\n",
    "pip2_predictiont = trained[1].predict(X_train)\n",
    "##Random forest\n",
    "pip3_predictiont = trained[2].predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSV\n",
      "0.9939611247405171\n",
      "\n",
      "\n",
      "\n",
      "Naive\n",
      "0.6755048122287224\n",
      "\n",
      "\n",
      "\n",
      "Random forest\n",
      "0.9999056425740706\n"
     ]
    }
   ],
   "source": [
    "##training Accuracy score\n",
    "print('LinearSV')\n",
    "print(accuracy_score(y_train,pip1_predictiont))\n",
    "print('\\n\\n')\n",
    "print('Naive')\n",
    "print(accuracy_score(y_train,pip2_predictiont))\n",
    "print('\\n\\n')\n",
    "print('Random forest')\n",
    "print(accuracy_score(y_train,pip3_predictiont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
